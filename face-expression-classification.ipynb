{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2021-10-23T15:55:20.034380Z","iopub.execute_input":"2021-10-23T15:55:20.034697Z","iopub.status.idle":"2021-10-23T15:55:24.783923Z","shell.execute_reply.started":"2021-10-23T15:55:20.034614Z","shell.execute_reply":"2021-10-23T15:55:24.783110Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_dir = \"../input/face-expression-recognition-dataset/images/train\"\nval_dir = \"../input/face-expression-recognition-dataset/images/validation\"","metadata":{"execution":{"iopub.status.busy":"2021-10-23T15:55:24.786830Z","iopub.execute_input":"2021-10-23T15:55:24.788025Z","iopub.status.idle":"2021-10-23T15:55:24.794080Z","shell.execute_reply.started":"2021-10-23T15:55:24.787994Z","shell.execute_reply":"2021-10-23T15:55:24.793419Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"batch_size=64\nimg_height=180\nimg_width=180\ntrain_ds = tf.keras.utils.image_dataset_from_directory(train_dir, \n                                                      validation_split = 0.2,\n                                                      subset = 'training',\n                                                      seed = 123,\n                                                      image_size = (img_height, img_width),\n                                                      batch_size = batch_size)\n\nval_ds = tf.keras.utils.image_dataset_from_directory(val_dir,\n                                                    validation_split=0.2,\n                                                    subset='validation',\n                                                    seed=123,\n                                                    image_size=(img_height, img_width),\n                                                    batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T15:55:24.795485Z","iopub.execute_input":"2021-10-23T15:55:24.795990Z","iopub.status.idle":"2021-10-23T15:55:41.820189Z","shell.execute_reply.started":"2021-10-23T15:55:24.795952Z","shell.execute_reply":"2021-10-23T15:55:41.818690Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nbatch_size = 32\nimg_height = 150\nimg_width = 150\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                  rotation_range=40,\n                                  width_shift_range=0.2,\n                                  height_shift_range=0.2,\n                                  shear_range=0.2,\n                                  zoom_range=0.2,\n                                  horizontal_flip=True,\n                                  fill_mode='nearest')\ntrain_ds = train_datagen.flow_from_directory(train_dir,\n                                            target_size = (img_height, img_width),\n                                            batch_size = batch_size,\n                                            class_mode='categorical')\nval_datagen = ImageDataGenerator(rescale=1./255)\nval_ds = val_datagen.flow_from_directory(val_dir,\n                                         target_size=(img_height, img_width),\n                                         batch_size=batch_size,\n                                         class_mode='categorical') \"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-10-23T15:55:41.821401Z","iopub.execute_input":"2021-10-23T15:55:41.821652Z","iopub.status.idle":"2021-10-23T15:55:41.830624Z","shell.execute_reply.started":"2021-10-23T15:55:41.821615Z","shell.execute_reply":"2021-10-23T15:55:41.829824Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class_names = train_ds.class_names\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T15:55:41.833604Z","iopub.execute_input":"2021-10-23T15:55:41.834184Z","iopub.status.idle":"2021-10-23T15:55:41.845397Z","shell.execute_reply.started":"2021-10-23T15:55:41.834146Z","shell.execute_reply":"2021-10-23T15:55:41.844233Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3,3,i+1)\n        plt.imshow(images[i].numpy().astype('uint8'))\n        plt.title(class_names[labels[i]])\n        plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-10-23T15:55:41.847111Z","iopub.execute_input":"2021-10-23T15:55:41.847305Z","iopub.status.idle":"2021-10-23T15:55:45.214172Z","shell.execute_reply.started":"2021-10-23T15:55:41.847276Z","shell.execute_reply":"2021-10-23T15:55:45.212818Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"for image_batch, labels_batch in train_ds:\n    print(image_batch.shape)\n    print(labels_batch.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2021-10-23T15:55:45.215200Z","iopub.execute_input":"2021-10-23T15:55:45.215444Z","iopub.status.idle":"2021-10-23T15:55:45.849256Z","shell.execute_reply.started":"2021-10-23T15:55:45.215412Z","shell.execute_reply":"2021-10-23T15:55:45.848440Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\"\"\"\"\nAUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE) \"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-10-23T15:55:45.850753Z","iopub.execute_input":"2021-10-23T15:55:45.851228Z","iopub.status.idle":"2021-10-23T15:55:45.857200Z","shell.execute_reply.started":"2021-10-23T15:55:45.851189Z","shell.execute_reply":"2021-10-23T15:55:45.856417Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Early Stopping","metadata":{}},{"cell_type":"code","source":"callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T15:55:45.858760Z","iopub.execute_input":"2021-10-23T15:55:45.859467Z","iopub.status.idle":"2021-10-23T15:55:45.866121Z","shell.execute_reply.started":"2021-10-23T15:55:45.859410Z","shell.execute_reply":"2021-10-23T15:55:45.865286Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Data augmentation","metadata":{}},{"cell_type":"code","source":"data_augmentation = keras.Sequential([\n    layers.RandomFlip(\"horizontal\",\n                      input_shape=(img_height,\n                                   img_width,\n                                   3)),\n    layers.RandomRotation(0.1),\n    layers.RandomZoom(0.1),\n])","metadata":{"execution":{"iopub.status.busy":"2021-10-23T15:55:45.867424Z","iopub.execute_input":"2021-10-23T15:55:45.867801Z","iopub.status.idle":"2021-10-23T15:55:46.013952Z","shell.execute_reply.started":"2021-10-23T15:55:45.867751Z","shell.execute_reply":"2021-10-23T15:55:46.013161Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T15:55:46.015500Z","iopub.execute_input":"2021-10-23T15:55:46.015750Z","iopub.status.idle":"2021-10-23T15:55:46.022677Z","shell.execute_reply.started":"2021-10-23T15:55:46.015717Z","shell.execute_reply":"2021-10-23T15:55:46.022052Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Create, compile and train the Model","metadata":{}},{"cell_type":"code","source":"num_classes = 7\n\nmodel = Sequential([\n    data_augmentation,\n    layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n    layers.Conv2D(32,(3,3), padding='same', activation='relu'),\n    layers.MaxPooling2D(2,2),\n    layers.Conv2D(32,(3,3), padding='same', activation='relu'),\n    layers.MaxPooling2D(2,2),\n    layers.Conv2D(64,(3,3), padding='same', activation='relu'),\n    layers.MaxPooling2D(2,2),\n    layers.Conv2D(128,(3,3), padding='same', activation='relu'),\n    layers.MaxPooling2D(2,2),\n    layers.Conv2D(256,(3,3), padding='same', activation='relu'),\n    layers.MaxPooling2D(2,2),\n    layers.Conv2D(512,(3,3), padding='same', activation='relu'),\n    layers.MaxPooling2D(2,2),\n    layers.Conv2D(512,(3,3), padding='same', activation='relu'),\n    layers.MaxPooling2D(2,2),\n    layers.Dropout(0.2),\n    layers.Flatten(),\n    layers.Dense(512, activation='relu'),\n    layers.Dense(num_classes, activation = 'softmax')\n])\n","metadata":{"execution":{"iopub.status.busy":"2021-10-23T16:31:37.505105Z","iopub.execute_input":"2021-10-23T16:31:37.505367Z","iopub.status.idle":"2021-10-23T16:31:37.723659Z","shell.execute_reply.started":"2021-10-23T16:31:37.505338Z","shell.execute_reply":"2021-10-23T16:31:37.722931Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n              loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-10-23T16:31:37.725103Z","iopub.execute_input":"2021-10-23T16:31:37.725815Z","iopub.status.idle":"2021-10-23T16:31:37.735666Z","shell.execute_reply.started":"2021-10-23T16:31:37.725775Z","shell.execute_reply":"2021-10-23T16:31:37.734777Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"epochs=80\nhistory = model.fit(train_ds, validation_data = val_ds,\n                    epochs= epochs,\n                    callbacks=[callback])","metadata":{"execution":{"iopub.status.busy":"2021-10-23T16:31:37.737314Z","iopub.execute_input":"2021-10-23T16:31:37.737570Z","iopub.status.idle":"2021-10-23T17:07:29.629260Z","shell.execute_reply.started":"2021-10-23T16:31:37.737536Z","shell.execute_reply":"2021-10-23T17:07:29.628472Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## Visualize training results","metadata":{}},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T17:07:29.632797Z","iopub.execute_input":"2021-10-23T17:07:29.633010Z","iopub.status.idle":"2021-10-23T17:07:29.965736Z","shell.execute_reply.started":"2021-10-23T17:07:29.632984Z","shell.execute_reply":"2021-10-23T17:07:29.964993Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}